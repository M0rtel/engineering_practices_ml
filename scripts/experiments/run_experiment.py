"""–°–∫—Ä–∏–ø—Ç –¥–ª—è –∑–∞–ø—É—Å–∫–∞ ML —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ —Å —Ç—Ä–µ–∫–∏–Ω–≥–æ–º —á–µ—Ä–µ–∑ DVC."""

import argparse
import json
import pickle  # nosec B403
from pathlib import Path
from typing import Any

import pandas as pd
import yaml
from sklearn.ensemble import (
    AdaBoostRegressor,
    GradientBoostingRegressor,
    RandomForestRegressor,
)
from sklearn.linear_model import ElasticNet, Lasso, LinearRegression, Ridge
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.neighbors import KNeighborsRegressor
from sklearn.svm import SVR
from sklearn.tree import DecisionTreeRegressor

# –ü—É—Ç–∏
DATA_DIR = Path("data/processed")
MODELS_DIR = Path("models")
REPORTS_DIR = Path("reports")
CONFIG_DIR = Path("config")

# –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
MODELS_DIR.mkdir(parents=True, exist_ok=True)
(REPORTS_DIR / "metrics").mkdir(parents=True, exist_ok=True)
(REPORTS_DIR / "experiments").mkdir(parents=True, exist_ok=True)


def load_data() -> tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è."""
    train_df = pd.read_csv(DATA_DIR / "train.csv")
    test_df = pd.read_csv(DATA_DIR / "test.csv")

    feature_cols = [
        "fixed acidity",
        "volatile acidity",
        "citric acid",
        "residual sugar",
        "chlorides",
        "free sulfur dioxide",
        "total sulfur dioxide",
        "density",
        "pH",
        "sulphates",
        "alcohol",
    ]
    target_col = "quality"

    X_train = train_df[feature_cols]
    y_train = train_df[target_col]
    X_test = test_df[feature_cols]
    y_test = test_df[target_col]

    return X_train, X_test, y_train, y_test


def get_model(model_name: str, **params: Any) -> Any:
    """–°–æ–∑–¥–∞—Ç—å –º–æ–¥–µ–ª—å –ø–æ –∏–º–µ–Ω–∏."""
    models = {
        "linear": LinearRegression,
        "ridge": Ridge,
        "lasso": Lasso,
        "elasticnet": ElasticNet,
        "knn": KNeighborsRegressor,
        "svr": SVR,
        "dt": DecisionTreeRegressor,
        "rf": RandomForestRegressor,
        "ada": AdaBoostRegressor,
        "gb": GradientBoostingRegressor,
    }

    if model_name not in models:
        raise ValueError(f"Unknown model: {model_name}")

    return models[model_name](**params)


def train_and_evaluate(
    model_name: str, params: dict[str, Any], experiment_id: str
) -> tuple[dict[str, float], Path]:
    """–û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –∏ –æ—Ü–µ–Ω–∏—Ç—å –µ—ë."""
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    X_train, X_test, y_train, y_test = load_data()

    # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
    model = get_model(model_name, **params)

    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º random_state —Ç–æ–ª—å–∫–æ –¥–ª—è –º–æ–¥–µ–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –µ–≥–æ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç
    if "random_state" in model.get_params():
        model.set_params(random_state=42)

    # –û–±—É—á–∞–µ–º
    print(f"ü§ñ –û–±—É—á–µ–Ω–∏–µ {model_name}...")
    model.fit(X_train, y_train)

    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    y_pred_train = model.predict(X_train)
    y_pred_test = model.predict(X_test)

    # –ú–µ—Ç—Ä–∏–∫–∏
    metrics = {
        "train_mse": float(mean_squared_error(y_train, y_pred_train)),
        "train_rmse": float(mean_squared_error(y_train, y_pred_train) ** 0.5),
        "train_mae": float(mean_absolute_error(y_train, y_pred_train)),
        "train_r2": float(r2_score(y_train, y_pred_train)),
        "test_mse": float(mean_squared_error(y_test, y_pred_test)),
        "test_rmse": float(mean_squared_error(y_test, y_pred_test) ** 0.5),
        "test_mae": float(mean_absolute_error(y_test, y_pred_test)),
        "test_r2": float(r2_score(y_test, y_pred_test)),
    }

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
    model_path = MODELS_DIR / f"{experiment_id}_model.pkl"
    with open(model_path, "wb") as f:
        pickle.dump(model, f)  # nosec B301

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
    metrics_path = REPORTS_DIR / "metrics" / f"{experiment_id}_metrics.json"
    with open(metrics_path, "w") as f:
        json.dump(metrics, f, indent=2)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    params_path = REPORTS_DIR / "experiments" / f"{experiment_id}_params.json"
    experiment_data = {
        "experiment_id": experiment_id,
        "model_name": model_name,
        "params": params,
        "metrics": metrics,
    }
    with open(params_path, "w") as f:
        json.dump(experiment_data, f, indent=2)

    print(f"‚úÖ –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç {experiment_id} –∑–∞–≤–µ—Ä—à–µ–Ω")
    print(f"  Test R¬≤: {metrics['test_r2']:.4f}")
    print(f"  Test RMSE: {metrics['test_rmse']:.4f}")

    return metrics, model_path


def main() -> None:
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    parser = argparse.ArgumentParser(description="–ó–∞–ø—É—Å–∫ ML —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞")
    parser.add_argument("--model", type=str, required=True, help="–ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏")
    parser.add_argument("--params", type=str, help="JSON —Å—Ç—Ä–æ–∫–∞ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏")
    parser.add_argument("--experiment-id", type=str, help="ID —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞")
    parser.add_argument("--config", type=str, help="–ü—É—Ç—å –∫ YAML –∫–æ–Ω—Ñ–∏–≥—É")

    args = parser.parse_args()

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    if args.config:
        with open(args.config) as f:
            config = yaml.safe_load(f)
        params = config.get("params", {})
        experiment_id = config.get("experiment_id", args.experiment_id or "exp_1")
    elif args.params:
        params = json.loads(args.params)
        experiment_id = args.experiment_id or "exp_1"
    else:
        params = {}
        experiment_id = args.experiment_id or "exp_1"

    # –ó–∞–ø—É—Å–∫–∞–µ–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç
    train_and_evaluate(args.model, params, experiment_id)


if __name__ == "__main__":
    main()
