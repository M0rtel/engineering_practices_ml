"""–°–∫—Ä–∏–ø—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏."""

import argparse
import json
import pickle  # nosec B403
from pathlib import Path
from typing import Any

import pandas as pd
import yaml
from sklearn.base import BaseEstimator
from sklearn.ensemble import (
    AdaBoostRegressor,
    GradientBoostingRegressor,
    RandomForestRegressor,
)
from sklearn.linear_model import ElasticNet, Lasso, LinearRegression, Ridge
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.neighbors import KNeighborsRegressor
from sklearn.svm import SVR
from sklearn.tree import DecisionTreeRegressor

from src.data_science_project.config_models import TrainingConfig

# –ü—É—Ç–∏
TRAIN_DATA = Path("data/processed/train.csv")
MODELS_DIR = Path("models")
REPORTS_DIR = Path("reports")

# –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
MODELS_DIR.mkdir(parents=True, exist_ok=True)
(REPORTS_DIR / "metrics").mkdir(parents=True, exist_ok=True)


def get_model(model_type: str, params: dict[str, Any]) -> BaseEstimator:
    """
    –°–æ–∑–¥–∞—Ç—å –º–æ–¥–µ–ª—å –ø–æ —Ç–∏–ø—É.

    Args:
        model_type: –¢–∏–ø –º–æ–¥–µ–ª–∏
        params: –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏

    Returns:
        –û–±—ä–µ–∫—Ç –º–æ–¥–µ–ª–∏ scikit-learn
    """
    models = {
        "linear": LinearRegression,
        "ridge": Ridge,
        "lasso": Lasso,
        "elasticnet": ElasticNet,
        "knn": KNeighborsRegressor,
        "svr": SVR,
        "dt": DecisionTreeRegressor,
        "rf": RandomForestRegressor,
        "ada": AdaBoostRegressor,
        "gb": GradientBoostingRegressor,
    }

    if model_type not in models:
        raise ValueError(f"Unknown model type: {model_type}")

    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º random_state —Ç–æ–ª—å–∫–æ –¥–ª—è –º–æ–¥–µ–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –µ–≥–æ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç
    model = models[model_type](**params)
    if "random_state" in model.get_params() and "random_state" not in params:
        model.set_params(random_state=42)

    return model


def train_model(config_file: Path, model_type: str | None = None) -> None:
    """
    –û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å.

    Args:
        config_file: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        model_type: –¢–∏–ø –º–æ–¥–µ–ª–∏ (–ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é)
    """
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    with open(config_file) as f:
        config_dict = yaml.safe_load(f)

    # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª—å—é
    training_config_dict = {
        "data": config_dict["data"],
    }
    if "model" in config_dict:
        training_config_dict["model"] = config_dict["model"]

    training_config = TrainingConfig(**training_config_dict)

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –º–æ–¥–µ–ª–∏
    if model_type:
        model_type_final = model_type
    elif "model" in config_dict and "model_type" in config_dict["model"]:
        model_type_final = config_dict["model"]["model_type"]
    else:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ train –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        model_type_final = "rf"
        if "train" in config_dict:
            {
                "n_estimators": config_dict["train"].get("n_estimators", 100),
                "max_depth": config_dict["train"].get("max_depth", 10),
                "min_samples_split": config_dict["train"].get("min_samples_split", 2),
                "min_samples_leaf": config_dict["train"].get("min_samples_leaf", 1),
                "random_state": config_dict["train"].get("random_state", 42),
            }
        else:
            pass

    # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
    if "model" in config_dict and "params" in config_dict["model"]:
        model_params = config_dict["model"]["params"]
    elif "train" in config_dict:
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ train –ø–æ–¥—Ö–æ–¥—è—Ç —Ç–æ–ª—å–∫–æ –¥–ª—è Random Forest
        # –î–ª—è –¥—Ä—É–≥–∏—Ö –º–æ–¥–µ–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ random_state, –µ—Å–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è
        if model_type_final == "rf":
            model_params = {
                "n_estimators": config_dict["train"].get("n_estimators", 100),
                "max_depth": config_dict["train"].get("max_depth", 10),
                "min_samples_split": config_dict["train"].get("min_samples_split", 2),
                "min_samples_leaf": config_dict["train"].get("min_samples_leaf", 1),
                "random_state": config_dict["train"].get("random_state", 42),
            }
        else:
            # –î–ª—è –¥—Ä—É–≥–∏—Ö –º–æ–¥–µ–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ random_state, –µ—Å–ª–∏ –µ—Å—Ç—å
            model_params = {}
            if config_dict["train"].get("random_state"):
                model_params["random_state"] = config_dict["train"]["random_state"]
    else:
        model_params = {}

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    print("üìä –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è...")
    train_df = pd.read_csv(TRAIN_DATA)

    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    data_config = training_config.data
    target_col = data_config.target_column
    feature_cols = data_config.feature_columns

    X_train = train_df[feature_cols]
    y_train = train_df[target_col]

    # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    print(f"ü§ñ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏: {model_type_final}...")
    model = get_model(model_type_final, model_params)
    model.fit(X_train, y_train)

    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ train
    y_pred_train = model.predict(X_train)

    # –ú–µ—Ç—Ä–∏–∫–∏
    metrics = {
        "train_mse": float(mean_squared_error(y_train, y_pred_train)),
        "train_rmse": float(mean_squared_error(y_train, y_pred_train) ** 0.5),
        "train_mae": float(mean_absolute_error(y_train, y_pred_train)),
        "train_r2": float(r2_score(y_train, y_pred_train)),
        "model_type": model_type_final,
    }

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
    model_path = MODELS_DIR / "model.pkl"
    with open(model_path, "wb") as f:
        pickle.dump(model, f)  # nosec B301

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
    with open(REPORTS_DIR / "metrics" / "model_metrics.json", "w") as f:
        json.dump(metrics, f, indent=2)

    print("‚úÖ –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞!")
    print(f"  Model: {model_type_final}")
    print(f"  Train R¬≤: {metrics['train_r2']:.4f}")
    print(f"  Train RMSE: {metrics['train_rmse']:.4f}")
    print(f"  –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {model_path}")


def main() -> None:
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    parser = argparse.ArgumentParser(description="–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏")
    parser.add_argument("--config", type=str, default="config/train_params.yaml")
    parser.add_argument("--model-type", type=str, help="–¢–∏–ø –º–æ–¥–µ–ª–∏")
    args = parser.parse_args()

    config_file = Path(args.config)
    if not config_file.exists():
        raise FileNotFoundError(f"–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {config_file}")

    train_model(config_file, args.model_type)


if __name__ == "__main__":
    main()
