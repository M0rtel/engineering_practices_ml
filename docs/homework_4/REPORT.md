# Отчет о настройке автоматизации ML пайплайнов

## Введение

Настроена система автоматизации ML пайплайнов с использованием DVC Pipelines для оркестрации и Pydantic для управления конфигурациями. Система включает мониторинг выполнения, валидацию данных и поддержку различных алгоритмов машинного обучения.

## 1. Настройка выбранного инструмента оркестрации (4 балла)

### 1.1. Установка и настройка DVC Pipelines

DVC уже установлен и настроен (см. ДЗ 2). Для автоматизации пайплайнов используется встроенная функциональность DVC Pipelines.

**Проверка версии:**
```bash
dvc --version
```

**Скриншот:** Версия DVC и структура пайплайна
*(Здесь должен быть скриншот вывода `dvc --version` и структуры `dvc.yaml`)*

### 1.2. Создание workflow для ML пайплайна

Создан расширенный workflow в `dvc.yaml` с следующими стадиями:

1. **prepare_data** - подготовка данных
2. **validate_data** - валидация данных
3. **train_model** - обучение модели
4. **evaluate_model** - оценка модели
5. **monitor_pipeline** - мониторинг выполнения

**Конфигурация пайплайна (`dvc.yaml`):**
```yaml
stages:
  prepare_data:
    cmd: python scripts/data/prepare_data.py --config ${config_file}
    deps:
      - data/raw/WineQT.csv
      - ${config_file}
    params:
      - config_file
    outs:
      - data/processed/train.csv
      - data/processed/test.csv
```

**Параметры пайплайна (`params.yaml`):**
```yaml
config_file: config/train_params.yaml
model_type: rf
enable_validation: true
enable_monitoring: true
```

**Скриншот:** Структура DVC pipeline
*(Здесь должен быть скриншот содержимого `dvc.yaml`)*

### 1.3. Настройка зависимостей между этапами

Зависимости настроены через `deps` в каждой стадии:

- `prepare_data` зависит от исходных данных и конфигурации
- `validate_data` зависит от `prepare_data` (обработанных данных)
- `train_model` зависит от `prepare_data` и конфигурации
- `evaluate_model` зависит от `train_model` и тестовых данных
- `monitor_pipeline` зависит от `evaluate_model` (метрик оценки)

**Управление параметрами:**
- Параметры хранятся в `params.yaml`
- Каждая стадия указывает используемые параметры в секции `params`
- Параметры отслеживаются DVC для определения необходимости перезапуска стадий

**Визуализация зависимостей:**
```bash
dvc dag
```

**Скриншот:** Граф зависимостей пайплайна
*(Здесь должен быть скриншот вывода `dvc dag`)*

### 1.4. Реализация кэширования и параллельного выполнения

**Кэширование:**
- DVC автоматически кэширует результаты выполнения стадий
- Кэширование основано на хешах зависимостей (deps) и параметров (params)
- DVC автоматически определяет, нужно ли перезапускать стадию

**Параллельное выполнение:**
- DVC поддерживает параллельное выполнение независимых стадий
- Для запуска: `dvc repro --jobs 4`
- Стадии `validate_data` и `train_model` могут выполняться параллельно после `prepare_data`

**Изменение параметров:**
- Создана утилита `scripts/pipeline/run_with_params.py` для изменения параметров
- Использование: `poetry run python scripts/pipeline/run_with_params.py train_model -S model_type=ridge`
- Или изменение `params.yaml` напрямую и запуск `dvc repro`

**Скриншот:** Результат выполнения пайплайна с кэшированием
*(Здесь должен быть скриншот вывода `dvc repro` с информацией о кэшировании)*

## 2. Настройка выбранного инструмента конфигураций (3 балла)

### 2.1. Настройка Pydantic для управления конфигурациями

**Установка:**
```toml
pydantic = "^2.5.0"
pydantic-settings = "^2.1.0"
```

**Скриншот:** Установка Pydantic через Poetry
*(Здесь должен быть скриншот вывода `poetry add pydantic pydantic-settings`)*

### 2.2. Создание конфигураций для разных алгоритмов

Созданы Pydantic модели для различных типов моделей:

- `DataConfig` - конфигурация данных
- `ModelConfig` - конфигурация модели
- `TrainingConfig` - полная конфигурация обучения
- Параметры для: Linear, Ridge, Lasso, ElasticNet, KNN, SVR, Decision Tree, Random Forest, AdaBoost, Gradient Boosting

**Пример конфигурации:**
```python
class RandomForestParams(ModelParams):
    n_estimators: int = Field(default=100, ge=1)
    max_depth: int | None = Field(default=None, ge=1)
    min_samples_split: int = Field(default=2, ge=2)
    min_samples_leaf: int = Field(default=1, ge=1)
```

**Скриншот:** Структура Pydantic моделей
*(Здесь должен быть скриншот содержимого `src/data_science_project/config_models.py`)*

### 2.3. Настройка валидации конфигураций

Pydantic автоматически валидирует конфигурации:

- Проверка типов данных
- Проверка диапазонов значений (ge, le, gt, lt)
- Проверка обязательных полей
- Валидация через Field constraints

**Пример валидации:**
```python
alpha: float = Field(default=1.0, gt=0.0)  # alpha > 0
test_size: float = Field(default=0.2, ge=0.0, le=1.0)  # 0 <= test_size <= 1
```

**Скриншот:** Пример ошибки валидации
*(Здесь должен быть скриншот вывода ошибки валидации при неверных параметрах)*

### 2.4. Создание системы композиции конфигураций

Конфигурации могут быть скомпонованы из базовых моделей:

```python
class TrainingConfig(BaseModel):
    data: DataConfig
    model: ModelConfig
    experiment_id: str | None = None
```

**Скриншот:** Пример композиции конфигураций
*(Здесь должен быть скриншот примера использования композиции)*

## 3. Интеграция и тестирование (2 балла)

### 3.1. Интеграция выбранных инструментов

**Интеграция Pydantic с DVC:**
- Скрипты используют Pydantic модели для загрузки и валидации конфигураций
- Конфигурации передаются через параметры DVC pipeline (`params.yaml`)
- Валидация выполняется автоматически при загрузке конфигурации
- Все скрипты (`prepare_data.py`, `validate_data.py`, `train_model.py`, `evaluate_model.py`) интегрированы с Pydantic

**Утилита для изменения параметров:**
- Создана `scripts/pipeline/run_with_params.py` для удобного изменения параметров
- Поддерживает синтаксис `-S PARAM=VALUE` (как в `dvc exp run`)
- Автоматически преобразует типы (bool, int, float, str)
- Обновляет `params.yaml` и запускает `dvc repro`

**Скриншот:** Интеграция в скриптах
*(Здесь должен быть скриншот примера использования Pydantic в скриптах)*

### 3.2. Создание системы мониторинга выполнения

Создан модуль `src/data_science_project/pipeline_monitor.py`:

- Отслеживание статуса каждой стадии
- Измерение времени выполнения
- Сохранение метрик и ошибок
- Генерация отчетов

**Использование:**
```python
monitor = PipelineMonitor()
monitor.start_stage("prepare_data")
monitor.complete_stage("prepare_data", metrics)
monitor.save_report()
```

**Скриншот:** Отчет мониторинга
*(Здесь должен быть скриншот содержимого отчета мониторинга)*

### 3.3. Настройка уведомлений о результатах

Реализованы уведомления через функцию `notify_completion()`:

- Вывод статуса завершения пайплайна
- Путь к отчету
- Сводка выполнения

**Скриншот:** Уведомление о завершении
*(Здесь должен быть скриншот вывода уведомления)*

### 3.4. Тестирование воспроизводимости

**Тест полного пайплайна:**
```bash
# Очистка результатов
rm -rf data/processed/* models/* reports/metrics/* reports/plots/*

# Воспроизведение
dvc repro

# Проверка
ls -lh models/ reports/metrics/
```

**Скриншот:** Результаты тестирования воспроизводимости
*(Здесь должен быть скриншот успешного выполнения `dvc repro`)*

## 4. Отчет о проделанной работе (1 балл)

### 4.1. Отчет в формате Markdown

Отчет создан в `docs/homework_4/REPORT.md` и включает:
- Описание настройки DVC Pipelines
- Описание настройки Pydantic
- Интеграцию инструментов
- Систему мониторинга
- Места для скриншотов

### 4.2. Описание настройки инструментов

В отчете описаны:
1. **DVC Pipelines** - установка, workflow, зависимости, кэширование
2. **Pydantic** - установка, модели конфигураций, валидация, композиция
3. **Интеграция** - использование Pydantic в скриптах, мониторинг, уведомления
4. **Тестирование** - воспроизводимость пайплайна

### 4.3. Скриншоты результатов

В отчете предусмотрены места для скриншотов:
1. Версия DVC и структура пайплайна
2. Структура DVC pipeline
3. Граф зависимостей пайплайна
4. Результат выполнения пайплайна с кэшированием
5. Установка Pydantic через Poetry
6. Структура Pydantic моделей
7. Пример ошибки валидации
8. Пример композиции конфигураций
9. Интеграция в скриптах
10. Отчет мониторинга
11. Уведомление о завершении
12. Результаты тестирования воспроизводимости

### 4.4. Сохранение в Git репозитории

Отчет сохранен в `docs/homework_4/REPORT.md` и включен в Git репозиторий.

**Скриншот:** Отчет в Git репозитории
*(Здесь должен быть скриншот файла REPORT.md в GitHub)*

## Заключение

Настроена полноценная система автоматизации ML пайплайнов:

✅ **DVC Pipelines настроен** - workflow с 5 стадиями (prepare_data, validate_data, train_model, evaluate_model, monitor_pipeline), зависимости, кэширование, параллельное выполнение
✅ **Pydantic настроен** - модели конфигураций для 10 типов моделей (linear, ridge, lasso, elasticnet, knn, svr, dt, rf, ada, gb), валидация параметров, композиция конфигураций
✅ **Интеграция выполнена** - Pydantic интегрирован во все скрипты пайплайна, мониторинг работает, утилита для изменения параметров создана
✅ **Мониторинг создан** - отслеживание стадий, метрики, отчеты, уведомления
✅ **Утилита для параметров** - `run_with_params.py` для удобного изменения параметров через `-S PARAM=VALUE`
✅ **Воспроизводимость протестирована** - пайплайн успешно воспроизводится через `dvc repro`
✅ **Отчет создан** - с описанием всех настроек и местами для скриншотов

Все инструменты настроены, протестированы и готовы к использованию.
