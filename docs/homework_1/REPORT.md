# Отчет о настройке рабочего места Data Scientist

## Введение

Данный отчет описывает процесс настройки полноценного рабочего места для Data Science с использованием современных инженерных практик. Все инструменты настроены и автоматизированы для обеспечения воспроизводимости результатов.

## 1. Структура проекта (2 балла)

### 1.1. Создание структуры папок

Создана структура проекта с использованием подхода Cookiecutter, следующая лучшим практикам Data Science проектов:

```
engineering_practices_ml/
├── data/                    # Данные проекта
│   ├── raw/                # Исходные данные (WineQT.csv)
│   ├── processed/          # Обработанные данные
│   ├── external/          # Внешние данные
│   └── interim/            # Промежуточные данные
├── src/                    # Исходный код
│   ├── data_science_project/
│   ├── models/             # Модели машинного обучения
│   ├── features/           # Инженерия признаков
│   └── visualization/      # Визуализация
├── tests/                  # Тесты
│   ├── unit/               # Юнит-тесты
│   └── integration/        # Интеграционные тесты
├── notebooks/              # Jupyter notebooks
├── docs/                   # Документация
├── scripts/                # Вспомогательные скрипты
├── config/                 # Конфигурационные файлы
├── reports/                # Отчеты и результаты
│   ├── figures/            # Графики и визуализации
│   └── models/             # Сохраненные модели
└── .github/workflows/      # GitHub Actions (для будущего использования)
```

### 1.2. Шаблоны для новых проектов

Структура проекта создана по образцу Cookiecutter Data Science шаблона и может быть использована как шаблон для новых Data Science проектов. Все необходимые директории созданы с `.gitkeep` файлами для сохранения структуры в Git.

**Скриншот:** Структура проекта в файловом менеджере
*(Здесь должен быть скриншот структуры папок проекта)*

### 1.3. README с описанием проекта

Создан подробный `README.md`, включающий:
- Описание проекта
- Структуру проекта
- Инструкции по установке
- Руководство по использованию
- Описание инструментов качества кода
- Информацию о Git workflow

**Скриншот:** README.md в GitHub репозитории
*(Здесь должен быть скриншот README.md в интерфейсе GitHub)*

## 2. Качество кода (2 балла)

### 2.1. Pre-commit hooks

Настроены pre-commit hooks через `.pre-commit-config.yaml`:

**Установка:**
```bash
poetry run pre-commit install
```

**Проверяемые аспекты:**
- Удаление trailing whitespace
- Проверка конца файлов
- Проверка YAML, JSON, TOML файлов
- Проверка больших файлов
- Проверка конфликтов слияния
- Отладка statements

**Инструменты форматирования и линтинга:**
- Black (форматирование кода)
- isort (сортировка импортов)
- Ruff (быстрый линтер и форматтер)
- MyPy (статическая проверка типов)
- Bandit (проверка безопасности)

**Скриншот:** Результат работы pre-commit hooks при коммите
*(Здесь должен быть скриншот вывода pre-commit с результатами проверок)*

### 2.2. Форматирование кода

#### Black
- **Конфигурация:** `pyproject.toml`
- **Длина строки:** 88 символов
- **Целевая версия Python:** 3.10
- **Исключения:** `.eggs`, `.git`, `.venv`, `build`, `dist`

**Использование:**
```bash
poetry run black src tests main.py
```

**Скриншот:** Результат форматирования кода с помощью Black
*(Здесь должен быть скриншот до/после форматирования или вывода команды)*

#### isort
- **Профиль:** Black (совместимость)
- **Длина строки:** 88 символов
- **Многострочный вывод:** 3
- **Конфигурация:** `pyproject.toml`

**Использование:**
```bash
poetry run isort src tests main.py
```

#### Ruff
- **Длина строки:** 88 символов
- **Целевая версия:** Python 3.10
- **Правила:** E, W, F, I, B, C4, UP
- **Конфигурация:** `pyproject.toml`

**Использование:**
```bash
poetry run ruff check src tests main.py
poetry run ruff format src tests main.py
```

### 2.3. Линтеры

#### MyPy
- **Версия Python:** 3.10
- **Строгие проверки:** включены
- **Игнорирование импортов:** для sklearn, matplotlib, seaborn, jupyter
- **Конфигурация:** `pyproject.toml`

**Использование:**
```bash
poetry run mypy src
```

**Скриншот:** Результаты проверки типов MyPy
*(Здесь должен быть скриншот вывода MyPy с результатами проверки)*

**Настройки:**
- `warn_return_any = true`
- `disallow_untyped_defs = true`
- `disallow_incomplete_defs = true`
- `check_untyped_defs = true`
- `no_implicit_optional = true`

#### Bandit
- **Проверка безопасности кода**
- **Исключения:** тесты, виртуальные окружения
- **Пропуски:** B101 (assert_used)

**Использование:**
```bash
poetry run bandit -r src
```

**Скриншот:** Результаты проверки безопасности Bandit
*(Здесь должен быть скриншот вывода Bandit с результатами проверки)*

### 2.4. Конфигурационные файлы

Все инструменты настроены через единый файл `pyproject.toml`, что соответствует современным стандартам Python проектов.

## 3. Управление зависимостями (2 балла)

### 3.1. Poetry для управления зависимостями

Настроен Poetry как основной инструмент управления зависимостями.

**Основные зависимости:**
- pandas (2.1.0) - работа с данными
- numpy (1.24.0) - численные вычисления
- scikit-learn (1.3.0) - машинное обучение
- matplotlib (3.7.0) - визуализация
- seaborn (0.12.0) - статистическая визуализация
- jupyter (1.0.0) - интерактивные notebooks
- ipykernel (6.25.0) - ядро для Jupyter

**Зависимости для разработки:**
- black, isort, ruff - форматирование и линтинг
- mypy - проверка типов
- bandit - безопасность
- pre-commit - автоматизация проверок
- pytest, pytest-cov - тестирование

**Установка:**
```bash
# Установка Poetry
curl -sSL https://install.python-poetry.org | python3 -

# Установка зависимостей
poetry install

# Активация виртуального окружения
poetry shell
```

**Скриншот:** Результат установки зависимостей через Poetry
*(Здесь должен быть скриншот вывода команды poetry install)*

### 3.2. requirements.txt с точными версиями

Создан `requirements.txt` с точными версиями всех зависимостей для воспроизводимости:

```
pandas==2.1.0
numpy==1.24.3
scikit-learn==1.3.0
matplotlib==3.7.2
seaborn==0.12.2
jupyter==1.0.0
ipykernel==6.25.0
...
```

**Использование:**
```bash
pip install -r requirements.txt
```

### 3.3. Виртуальное окружение

Poetry автоматически создает и управляет виртуальным окружением:

```bash
# Создание окружения
poetry install

# Активация
poetry shell

# Информация об окружении
poetry env info
```

### 3.4. Dockerfile для контейнеризации

Создан `Dockerfile` для контейнеризации проекта:

**Особенности:**
- Базовый образ: Python 3.10-slim
- Установка Poetry
- Копирование зависимостей и установка
- Настройка PYTHONPATH
- Рабочая директория: /app

**Сборка и запуск:**
```bash
# Сборка образа
docker build -t engineering-practices-ml .

# Запуск контейнера
docker run -it engineering-practices-ml

# Или через docker-compose
docker-compose up
```

**Скриншот:** Успешная сборка Docker образа
*(Здесь должен быть скриншот вывода docker build)*

**Дополнительно:**
- Создан `.dockerignore` для исключения ненужных файлов
- Создан `docker-compose.yml` для упрощения работы с контейнерами

## 4. Git workflow (1 балл)

### 4.1. Настройка Git репозитория

Инициализирован Git репозиторий:
```bash
git init
git branch -m master main
git checkout -b develop
```

### 4.2. .gitignore для ML проекта

Создан комплексный `.gitignore`, включающий:

**Python:**
- `__pycache__/`, `*.pyc`, `*.pyo`
- Виртуальные окружения (`.venv`, `venv/`, `env/`)
- Файлы сборки (`build/`, `dist/`, `*.egg-info/`)

**Data Science специфичные:**
- Данные: `data/raw/*`, `data/processed/*`, `data/external/*`, `data/interim/*`
- Модели: `models/*.pkl`, `models/*.h5`, `models/*.joblib`
- Отчеты: `reports/figures/*`, `reports/models/*`
- Notebooks: `*.ipynb_checkpoints`

**Инструменты разработки:**
- Тесты: `.pytest_cache/`, `.coverage`, `htmlcov/`
- Типы: `.mypy_cache/`
- Безопасность: `bandit-report.json`
- IDE: `.vscode/`, `.idea/`

**Сохранение структуры:**
- Использованы `.gitkeep` файлы для пустых директорий

### 4.3. Структура веток

Настроена структура веток по модели Git Flow:

- **main** - основная ветка с рабочим кодом
- **develop** - ветка разработки
- **feature/*** - ветки для новых функций
- **bugfix/*** - ветки для исправления ошибок
- **hotfix/*** - ветки для срочных исправлений

**Документация:** Создан `docs/GIT_WORKFLOW.md` с подробным описанием рабочего процесса.

**Скриншот:** Структура веток в GitHub
*(Здесь должен быть скриншот веток в интерфейсе GitHub: main, develop, feature/*)*

### 4.4. GitHub Actions CI/CD

Создан `.github/workflows/ci.yml` для автоматизации:

**Стадии:**
1. **lint** - проверка кода (Black, isort, Ruff, MyPy, Bandit)
2. **test** - запуск тестов с покрытием
3. **build** - сборка Docker образа

**Особенности:**
- Автоматическая установка Poetry
- Генерация отчетов о покрытии кода
- Сборка Docker образа для main и develop веток
- Интеграция с GitHub Actions

**Скриншот:** Результаты выполнения CI/CD pipeline в GitHub Actions
*(Здесь должен быть скриншот успешного выполнения всех стадий CI/CD)*

## 5. Заключение

Настроено полноценное рабочее место для Data Science с использованием современных инженерных практик:

✅ **Структура проекта** - организована по образцу Cookiecutter
✅ **Качество кода** - автоматизированные проверки через pre-commit
✅ **Управление зависимостями** - Poetry + requirements.txt + Docker
✅ **Git workflow** - настроен Git Flow с документацией для GitHub
✅ **Воспроизводимость** - все автоматизировано для легкого воспроизведения

Все инструменты настроены, протестированы и готовы к использованию.

**Скриншот:** Общий вид проекта в GitHub репозитории
*(Здесь должен быть скриншот главной страницы репозитория в GitHub)*
